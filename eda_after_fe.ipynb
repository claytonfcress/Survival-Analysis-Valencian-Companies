{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valencia_data = pd.read_csv(rf'/mnt/c/Users/clayt/Data Science/UCM/TFM/Datos/Processed/valencia_data_feature_engineer.csv', encoding = 'latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_checker(data, xlabel, additional_layers=None):\n",
    "    \n",
    "    if additional_layers is None:\n",
    "        additional_layers = []\n",
    "\n",
    "    # Combine xlabel with additional layers for grouping\n",
    "    group_by_columns = [xlabel] + additional_layers + ['failure']\n",
    "    \n",
    "    # Group the data by xlabel, additional layers, and failure\n",
    "    grouped = data.groupby(group_by_columns)['company_name'].count().reset_index()\n",
    "    \n",
    "    # Pivot the grouped data to get 'failure' as columns\n",
    "    pivot = grouped.pivot_table(index=group_by_columns[:-1], columns='failure', values='company_name', fill_value=0)\n",
    "    \n",
    "    # Rename columns for clarity (0 = No failure, 1 = Failure)\n",
    "    pivot.columns = ['continuation', 'disolution']\n",
    "    \n",
    "    # Calculate total count of each group (sum of no_failure and failure)\n",
    "    pivot['total'] = pivot['continuation'] + pivot['disolution']\n",
    "    \n",
    "    # Calculate percentages for each failure status\n",
    "    pivot['perc_failure'] = ((pivot['disolution'] / pivot['total']) * 100).round(1)\n",
    "    pivot['perc_no_failure'] = ((pivot['continuation'] / pivot['total']) * 100).round(1)\n",
    "    \n",
    "    # Dropping the unnecessary columns for a cleaner output\n",
    "    pivot = pivot.drop(['continuation', 'disolution'], axis=1)\n",
    "    \n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(data, continuous_columns, hue='failure', kind='kde', fill=True, height=6, aspect=1.5, palette='deep'):\n",
    "    # Create a grid of subplots\n",
    "    num_vars = len(continuous_columns)\n",
    "    num_cols = 2  # Number of columns in the subplot grid\n",
    "    num_rows = (num_vars + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "    \n",
    "    # Set up the matplotlib figure\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * height * aspect, num_rows * height), constrained_layout=True)\n",
    "    \n",
    "    # Flatten the axes array for easy iteration\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, column in enumerate(continuous_columns):\n",
    "        # Create the KDE plot\n",
    "        sns.kdeplot(\n",
    "            data=data,\n",
    "            x=column,\n",
    "            hue=hue,\n",
    "            fill=fill,\n",
    "            palette=palette,\n",
    "            ax=axes[i]  # Pass the specific subplot axis\n",
    "        )\n",
    "        \n",
    "        # Set titles and labels\n",
    "        axes[i].set_title(f'Distribution of {column} by {hue}')\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel('Density')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(len(continuous_columns), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urbano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_checker(valencia_data, 'urbano')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant different between our target classes for urbano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=valencia_data, \n",
    "    x='competitors_500m',\n",
    "    hue='failure', \n",
    "    kind='kde', \n",
    "    fill=True, \n",
    "    height=6, \n",
    "    aspect=1.5, \n",
    "    palette='deep'\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Competitors 500m Radius Disolution and Continuation')\n",
    "plt.xlabel('Competitors within 500m')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=valencia_data, \n",
    "    x='competitors_1000m',\n",
    "    hue='failure', \n",
    "    kind='kde', \n",
    "    fill=True, \n",
    "    height=6, \n",
    "    aspect=1.5, \n",
    "    palette='deep'\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Competitors 1000m Radius Disolution and Continuation')\n",
    "plt.xlabel('Competitors within 1000m')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=valencia_data, \n",
    "    x='competitors_3000m',\n",
    "    hue='failure', \n",
    "    kind='kde', \n",
    "    fill=True, \n",
    "    height=6, \n",
    "    aspect=1.5, \n",
    "    palette='deep'\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Competitors 3000m Radius Disolution and Continuation')\n",
    "plt.xlabel('Competitors within 3000m')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no apparent significant difference in failure rates for any of the competitor indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sector Unemployment Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_columns = [f\"Sector {chr(i)} Ratio\" for i in range(ord('A'), ord('U') + 1)] + ['Sin Actividad Ratio', 'Total Ratio']\n",
    "plot_distributions(valencia_data, sector_columns, hue='failure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately there don't appear to be any significant differences in failure based on the distribution of the ratio of unemployed individuals per sector per municipio over the poulation in the municipio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Density Sector Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_columns = [f\"sector_{chr(i)}_density\" for i in range(ord('A'), ord('U') + 1)] \n",
    "plot_distributions(valencia_data, density_columns, hue='failure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to see if there is any significant difference classes based on the distributions of business density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_columns = valencia_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Create the feature matrix X by including only numeric columns\n",
    "X = valencia_data[numeric_columns]\n",
    "\n",
    "# Drop the target columns if present\n",
    "X = X.drop(columns=['duration', 'failure'], errors='ignore')  # Use errors='ignore' to avoid KeyError if columns are not present\n",
    "\n",
    "# Add a constant to the features matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Compute VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif['Feature'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Print the VIF DataFrame\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some extremely high VIF values. We will likely remove some of these columns with high multicollinearity further on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valencia_data.drop(columns = ['company_name'], inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
